---
title: "데이터 분석과 시각화"
search: true
categories:
  - Coding
  - Computer Science
  - Data Science
toc: true
toc_label: "데이터 분석과 시각화"
toc_sticky: true
last_modified_at: 2023-12-21T00:01:18
sidebar:
  nav: coding
---

## 시각화와 그래프

- `df.plot()`: 그래프 그리기

  - `y='col`, `y=['col1', 'col2']`: 원하는 column만 그래프로 보기
    - `df['col1'].plot()`, `df[['col1', 'col2']].plot()`과 동일
    - pandas Series에도 `plot` 함수 사용 가능
  - 그래프 종류 설정 ⇒ `kind` 옵션 활용

    1. 선 그래프(기본값): `kind='line'`
    2. 막대 그래프: `kind='bar'`
       - 가로 막대 그래프: `kind='barh'`
       - 쌓아올리기: `stacked=True`
       - x축: `x='col'`
    3. 파이 그래프: `kind='pie'`
    4. 히스토그램: `kind='hist'`
       - y축: `y='col'`
       - n개로 분할: `bins=n`
    5. 박스 플롯: `kind='box'`

       - 다섯 개의 통계값으로 표현

         ![박스 플롯](/assets/images/데이터%20사이언스/img2.png){: width="50%" height="50%"}

         - box: 25%(Q1) 지점부터 75%(Q3) 지점까지
         - whisker
           - Q1 지점부터 IQR(Interquartile Range, Q3 - Q1)의 1.5배 내에 있는 가장 멀리 떨어진 데이터 지점(또는 최솟값) 까지의 직선
           - Q3 지점부터 IQR의 1.5배 내에 있는 가장 멀리 떨어진 데이터 지점(또는 최댓값) 까지의 직선
         - outlier(이상점): whisker의 범위를 넘어가는 점

       - 박스가 짧을수록 데이터가 균일, 길수록 데이터가 분산

    6. 산점도(scatter plot): `kind='scatter'`
       - x축: `x='col1'`
       - y축: `y='col2'`

## Seaborn 시각화

- Statistical Data Visualization ⇒ 통계를 기본으로 한 데이터 시각화

1. PDF(PRobability Density Function): 확률 밀도 함수
   - 데이터셋의 분포를 나타냄
   - 특정 구간의 확률은 그래프 아래 그 구간의 면적과 동일
   - 그래프 아래 모든 면적을 더하면 1
2. KDE Plot(Kernel Density Estimation)
   - 불균일한 데이터를 부드러운 곡선으로 만들어 확률 밀도 함수 형태로 만듦 → 실제 데이터셋 분포와 다름
   - `sns.kdeplot(df['col'])`
     - `bw=x`: bandwidth. 추측의 정도 설정(클수록 곡선이 부드러워짐)
   - `sns.distplot(df['col'], bins=n)`: KDE Plot + 히스토그램
   - `sns.violinplot(y=df['col'])`: violinplot
     - KDE Plot을 90도 돌린 형태
     - Box Plot과는 다르게 violinplot은 분포 전체를 보여주는 특징이 있음
     - `hue='col'`: 카테고리별 색깔로 구분 가능
   - `sns.kdeplot(df['col1'], df['col2'])`: 등고선도
     - 산점도 + KDE Plot
3. LM Plot
   - 산점도 + 회귀선(regression line)
   - `sns.lmplot(data=df, x='col1', y='col2')`
4. 카테고리별 시각화
   - `sns.catplot(data=df, x='col1', y='col2', kind='box', hue='col3')`
     - `x`: x축. 카테고리
     - `y`: y축. 분포값
     - `kind`: `box`, `violin`, `strip`(점 형식으로 표시. 데이터 수 확인 용이), `swarm`(`strip` 형식에서 점들이 펼쳐져서 보임)
     - `hue`: 같은 x값에서 카테고리별 색깔로 구분 가능

## 통계 기본 상식

1. 평균(Mean)
   - 데이터들의 합 / 데이터 개수
   - 잘못되거나 특이한 데이터에 대해서 취약
2. 중간값(Median): 데이터셋에서 딱 중간에 있는 값
   - Q1: 중간값 포함 하위 데이터들 중에서 중간값. numpy/pandas에서는 $(\text{Length} - 1) \times 0.25$ 인덱스로 계산
   - Q2: 중간값
   - Q3: 중간값 포함 상위 데이터들 중에서 중간값. numpy/pandas에서는 $(\text{Length} - 1) \times 0.75$ 인덱스로 계산
   - _참고: 소수 인덱스는 두 정수 인덱스의 값 사이의 내분으로 계산_
3. (피어슨) 상관 계수((Pearson) Correlation Coefficient)
   - -1 ~ 1 값 가짐
   - `df.corr()`: DataFrame에 존재하는 숫자 데이터 사이의 상관 계수를 보여줌
   - `sns.heatmap(df.corr())`: 상관계수 시각화
     - 밝을수록 상관계수가 높음
     - `annot=True`: 숫자 표기

## Exploratory Data Analysis(EDA)

- 탐색적 데이터 분석(EDA)
  - 데이터셋을 다양한 관점에서 살펴보고 탐색하면서 인사이트를 찾는 것
  - 시각적인 방법, 통계적인 방법, ...
- 두 데이터의 연관성 확인 ⇒ `sns.jointplot(data=df, x='col1', y='col2')`

  ![jointplot](/assets/images/데이터%20사이언스/img3.png){: width="50%" height="50%"}

- 상관 관계 분석(Correlation Analysis) ⇒ `sns.heatmap` 활용
- 클러스터 분석(Cluster Analysis)

  - 데이터를 몇 가지 무리로 나누는 것
  - `sns.clustermap(df)` 활용

    ![clustermap](/assets/images/데이터%20사이언스/img4.png){: width="50%" height="50%"}

## 새로운 인사이트 발견하기

1. 새로운 값 계산하기
   - 모든 column의 합 구하기: `df.sum(axis='columns')`
2. 문자열 필터링
   - 포함: `df['col'].str.contains('text')`
   - 첫 시작: `df['col'].str.startswith('text')`
3. 문자열 분리: `df['col'].str.split()`
   - `n=1`: 첫 번째 띄어쓰기만 분리
   - `expand=True`: pandas DataFrame 형태로 출력
   - `pat='-'`: 분리 요소
4. 카테고리로 분류

   - `map`

     ```python
     mapping_dict = {
      'A': 'a',
      'B': 'b',
      ...
     }

     df["col"].map(mapping_dict)
     ```

   - `groupby`

     ```python
     groups = df.groupby('col')
     type(groups) # DataFrameGroupBy

     groups.count()  # 그룹별 개수
     groups.max()    # 그룹별 최댓값
     groups.mean()   # 그룹별 평균값
     groups.first()  # 그룹별 첫 번째 레코드
     groups.last()   # 그룹별 마지막 레코드

     groups.plot()   # 그룹별 그래프 그리기
     ```

5. 데이터 합치기: `pd.merge(df1, df2, on='col')`
   - `on`: merge의 기준이 되는 축
   - `how`: merge 방법
     1. `inner`: inner join(교집합)(기본값)
     2. `left`: left outer join(좌측 df 기준. 없으면 NaN)
     3. `right`: right outer join(우측 df 기준. 없으면 NaN)
     4. `outer`: full outer join(없으면 NaN)
